{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "len(os.listdir('C:/Users/vian8/Desktop/Tugas2/SNAPGRADE/inputs/cross_data_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been renamed successfully.\n"
     ]
    }
   ],
   "source": [
    "directory = 'C:/Users/vian8/Desktop/Tugas2/SNAPGRADE/inputs/cross_data_raw'\n",
    "\n",
    "files = os.listdir(directory)\n",
    "\n",
    "image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "\n",
    "for i, filename in enumerate(image_files, start=1):\n",
    "    old_path = os.path.join(directory, filename)\n",
    "    file_extension = os.path.splitext(filename)[1]\n",
    "    new_path = os.path.join(directory, f\"{i}{file_extension}\")\n",
    "    os.rename(old_path, new_path)\n",
    "\n",
    "print(\"Files have been renamed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def resize_image(image, target_size=(800, 1000)):\n",
    "  '''Resize the image while maintaining aspect ratio'''\n",
    "  h, w = image.shape[:2]\n",
    "  scale = min(target_size[1] / w, target_size[0] / h)\n",
    "  new_w = int(w * scale)\n",
    "  new_h = int(h * scale)\n",
    "  resized_image = cv2.resize(image, (new_w, new_h))\n",
    "  return resized_image\n",
    "\n",
    "def logarithmic_transformation(image, epsilon=1e-5):\n",
    "  '''Apply logarithmic transformation to the image with zero value handling'''\n",
    "  c = 255 / np.log(1 + np.max(image))\n",
    "  # Epsilon zero-handling technique\n",
    "  log_image = c * (np.log(1 + image + epsilon))\n",
    "  log_image = np.array(log_image, dtype=np.uint8)\n",
    "\n",
    "  return log_image\n",
    "\n",
    "def contrast_stretching(image):\n",
    "  min_val = np.min(image)\n",
    "  max_val = np.max(image)\n",
    "  stretched = (image - min_val) * (255 / (max_val - min_val))\n",
    "  return stretched.astype(np.uint8)\n",
    "\n",
    "def gaussian_blur(image, mode='Soft'):\n",
    "  if mode == 'Soft':\n",
    "    kernel_size = (3,3)\n",
    "  elif mode == 'Medium':\n",
    "    kernel_size = (5,5)\n",
    "  elif mode == 'Hard':\n",
    "    kernel_size = (7,7)\n",
    "  else:\n",
    "    raise ValueError(\"Mode must be 'Soft', 'Medium', or 'Hard'\")\n",
    "\n",
    "  return cv2.GaussianBlur(image, kernel_size, 0)\n",
    "\n",
    "def measure_blurriness(image):\n",
    "  # Apply the Laplacian operator to detect edges\n",
    "  laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "  # Variance of Laplacian\n",
    "  variance = laplacian.var()\n",
    "\n",
    "  return variance\n",
    "\n",
    "def adaptive_gaussian_blur(image, desired_blur=100, max_iterations=100):\n",
    "  # Measure initial blur level\n",
    "  initial_blur = measure_blurriness(image)\n",
    "\n",
    "  # Set a starting kernel size\n",
    "  kernel_size = 5\n",
    "\n",
    "  for iteration in range(max_iterations):\n",
    "      # Apply Gaussian blur with the current kernel size\n",
    "      blurred_image = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "      # Measure the blur after applying Gaussian blur\n",
    "      current_blur = measure_blurriness(blurred_image)\n",
    "\n",
    "      # If the current blur exceeds the desired blur, stop\n",
    "      if current_blur > desired_blur:\n",
    "          kernel_size += 2\n",
    "      else:\n",
    "        break\n",
    "\n",
    "  final_blurred_img = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "  final_blur = measure_blurriness(final_blurred_img)\n",
    "\n",
    "  print(f\"Initial Blur: {initial_blur}, Final Blur: {final_blur}, Kernel Size: {kernel_size}, Iterations: {iteration+1}\")\n",
    "\n",
    "  return final_blurred_img\n",
    "\n",
    "def clahe_equalization(image):\n",
    "  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "  equalized_img = clahe.apply(image)\n",
    "  return equalized_img\n",
    "\n",
    "def otsu_thresholding(image):\n",
    "  _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "  return binary_image\n",
    "\n",
    "def canny_edge_detection(image, low_threshold=50, high_threshold=150):\n",
    "  return cv2.Canny(image, low_threshold, high_threshold)\n",
    "\n",
    "def find_extreme_corners(contours):\n",
    "  '''Find the extreme corners of the image'''\n",
    "  all_points = np.vstack(contours)\n",
    "  top_left = all_points[np.argmin(all_points[:, :, 0] + all_points[:, :, 1])]\n",
    "  bottom_right = all_points[np.argmax(all_points[:, :, 0] + all_points[:, :, 1])]\n",
    "  top_right = all_points[np.argmax(all_points[:, :, 0] - all_points[:, :, 1])]\n",
    "  bottom_left = all_points[np.argmin(all_points[:, :, 0] - all_points[:, :, 1])]\n",
    "  return top_left[0], top_right[0], bottom_left[0], bottom_right[0]\n",
    "\n",
    "def apply_perspective_transformation(image, corners):\n",
    "  '''Apply perspective transformation to the image'''\n",
    "  tl, tr, bl, br = corners\n",
    "  width = int(max(np.linalg.norm(br - bl), np.linalg.norm(tr - tl)))\n",
    "  height = int(max(np.linalg.norm(tr - br), np.linalg.norm(tl - bl)))\n",
    "\n",
    "  dst_pts = np.array([\n",
    "      [0, 0],\n",
    "      [width - 1, 0],\n",
    "      [0, height - 1],\n",
    "      [width - 1, height - 1]\n",
    "  ], dtype=\"float32\")\n",
    "\n",
    "  src_pts = np.array([tl, tr, bl, br], dtype=\"float32\")\n",
    "\n",
    "  M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "  warped = cv2.warpPerspective(image, M, (width, height))\n",
    "  return warped\n",
    "\n",
    "def automatic_warp_transformation(image, target_size=(800, 1000)):\n",
    "  '''Automatic Cropping using Adaptive Warp Transformation'''\n",
    "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  resized_image = resize_image(gray_image, target_size)\n",
    "  brightened_image = logarithmic_transformation(resized_image)\n",
    "  contrast_image = contrast_stretching(brightened_image)\n",
    "  blurred_image = gaussian_blur(contrast_image, mode='Soft')\n",
    "  binary_image = otsu_thresholding(blurred_image)\n",
    "  edges = canny_edge_detection(binary_image)\n",
    "  contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  # Getting Contours (Drawing Contours in image, useful for debugging)\n",
    "  contour_image = cv2.cvtColor(binary_image, cv2.COLOR_GRAY2BGR)\n",
    "  cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "  corners = find_extreme_corners(contours)\n",
    "  for corner in corners:\n",
    "      cv2.circle(contour_image, tuple(corner), 5, (0, 0, 255), -1)\n",
    "\n",
    "  warped_image = apply_perspective_transformation(resized_image, corners)\n",
    "  print(f'Initial image {image.shape} processed to {warped_image.shape}')\n",
    "\n",
    "  return warped_image\n",
    "\n",
    "def automatic_warp_transformation_v2(image, target_size=(800, 1000)):\n",
    "  '''Automatic Cropping using Adaptive Warp Transformation'''\n",
    "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  resized_image = resize_image(gray_image, target_size)\n",
    "  \n",
    "  clahe = clahe_equalization(resized_image)\n",
    "  log_img = logarithmic_transformation(clahe)\n",
    "  contrast_img = contrast_stretching(log_img)\n",
    "  blurred_img = gaussian_blur(contrast_img)\n",
    "  binary_img = otsu_thresholding(blurred_img)\n",
    "  edges = canny_edge_detection(binary_img)\n",
    "  contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  # Getting Contours (Drawing Contours in image, useful for debugging)\n",
    "  contour_image = cv2.cvtColor(binary_img, cv2.COLOR_GRAY2BGR)\n",
    "  cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "  corners = find_extreme_corners(contours)\n",
    "  for corner in corners:\n",
    "      cv2.circle(contour_image, tuple(corner), 5, (0, 0, 255), -1)\n",
    "\n",
    "  warped_image = apply_perspective_transformation(resized_image, corners)\n",
    "  print(f'Initial image {image.shape} processed to {warped_image.shape}')\n",
    "\n",
    "  return warped_image\n",
    "\n",
    "def image_uniformization(master_image, student_image):\n",
    "  '''Precision Image Resizing'''\n",
    "  master_shape = master_image.shape\n",
    "  student_shape = student_image.shape\n",
    "\n",
    "  master_height = master_shape[0]\n",
    "  master_width = master_shape[1]\n",
    "\n",
    "  student_height = student_shape[0]\n",
    "  student_width = student_shape[1]\n",
    "\n",
    "  min_height = min(master_height, student_height)\n",
    "  min_width = min(master_width, student_width)\n",
    "\n",
    "  resized_master = cv2.resize(master_image, (min_width, min_height))\n",
    "  resized_student = cv2.resize(student_image, (min_width, min_height))\n",
    "\n",
    "  print(f'master_key {master_image.shape} and student_answer {student_image.shape} uniformed to {resized_master.shape}')\n",
    "\n",
    "  return resized_master, resized_student\n",
    "\n",
    "def morph_open(image):\n",
    "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "  eroded_img = cv2.erode(image, kernel, iterations = 1)\n",
    "  dilated_img = cv2.dilate(eroded_img, kernel, iterations = 1)\n",
    "\n",
    "  return dilated_img\n",
    "\n",
    "def core_preprocessing(image):\n",
    "  '''Core Preprocessing Module'''\n",
    "  blurred_img = gaussian_blur(image, mode='Hard')\n",
    "  contrast_img = contrast_stretching(blurred_img)\n",
    "  log_img = logarithmic_transformation(contrast_img)\n",
    "  binary_img = otsu_thresholding(log_img)\n",
    "  opened_img = morph_open(binary_img)\n",
    "\n",
    "  return opened_img\n",
    "\n",
    "def core_preprocessing_v2(image):\n",
    "  '''\n",
    "  Core Preprocessing Module V2:\n",
    "  - Uses CLAHE for lighting handling\n",
    "  - Uses Adaptive Gaussian Blur to ensure optimal thresholding\n",
    "  '''\n",
    "  clahe_img = clahe_equalization(image)\n",
    "  blurred_img = adaptive_gaussian_blur(clahe_img, desired_blur=100, max_iterations=100)\n",
    "  contrast_img = contrast_stretching(blurred_img)\n",
    "  log_img = logarithmic_transformation(contrast_img)\n",
    "  binary_img = otsu_thresholding(log_img)\n",
    "  opened_img = morph_open(binary_img)\n",
    "\n",
    "  return opened_img\n",
    "\n",
    "def draw_full_contours(contours, cont_image, radius = 7):\n",
    "  '''Draw Full Circles'''\n",
    "  for contour in contours:\n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] != 0:\n",
    "      cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "      cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "      # Draw a filled circle at the center of the contour\n",
    "      cv2.circle(cont_image, (cX, cY), radius, (0, 255, 0), -1)\n",
    "\n",
    "  return cont_image\n",
    "\n",
    "def extract_and_draw_contours(image):\n",
    "  contours, hierarchy = cv2.findContours(image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  unique_values = []\n",
    "  for columns in image:\n",
    "    for pixel in columns:\n",
    "      if pixel not in unique_values:\n",
    "        unique_values.append(pixel)\n",
    "\n",
    "  contour_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "  contour_image = draw_full_contours(contours, contour_image)\n",
    "\n",
    "  return contours, contour_image\n",
    "\n",
    "def extract_and_draw_circle_contours(image):\n",
    "  contours, hierarchy = cv2.findContours(image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  circle_contours = []\n",
    "  contour_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "  # radius_list = []\n",
    "  # contour_ar_list = []\n",
    "\n",
    "  for contour in contours:\n",
    "      # Approximate the enclosing circle for each contour\n",
    "      (x, y), radius = cv2.minEnclosingCircle(contour)\n",
    "      circle_area = np.pi * (radius ** 2)\n",
    "\n",
    "      # if radius not in radius_list:\n",
    "      #   radius_list.append(radius)\n",
    "\n",
    "      # if contour_area not in contour_ar_list:\n",
    "      #   contour_ar_list.append(contour_area)\n",
    "\n",
    "      # Calculate the actual contour area\n",
    "      contour_area = cv2.contourArea(contour)\n",
    "\n",
    "      # Check if the contour area is approximately equal to the circle area\n",
    "      # Tolerance range for being \"circular\"\n",
    "      if radius < 5:\n",
    "          if 0.6 <= contour_area / circle_area <= 1.4:\n",
    "              circle_contours.append(contour)\n",
    "      else:\n",
    "          if 0.8 <= contour_area / circle_area <= 1.2:\n",
    "              circle_contours.append(contour)\n",
    "\n",
    "  # contour_image = cv2.drawContours(contour_image, circle_contours, -1, (0, 255, 0), thickness=2)\n",
    "  contour_image = draw_full_contours(circle_contours, contour_image)\n",
    "\n",
    "  return circle_contours, contour_image\n",
    "\n",
    "def soft_morph_open(image):\n",
    "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "  eroded_img = cv2.erode(image, kernel, iterations = 1)\n",
    "  dilated_img = cv2.dilate(eroded_img, kernel, iterations = 1)\n",
    "\n",
    "  return dilated_img\n",
    "\n",
    "def final_scoring(new_student, processed_student, master_contours):\n",
    "  '''Final Score Calculation'''\n",
    "  test_answer = processed_student.copy()\n",
    "  # drawing the Answer Key to the Student's test answer, extracting the mistakes information\n",
    "  check_answers = draw_full_contours(master_contours, test_answer)\n",
    "\n",
    "  # open the image to remove noise\n",
    "  final_sheet = soft_morph_open(check_answers)\n",
    "\n",
    "  # fetching mistakes contours\n",
    "  final_contours, img = extract_and_draw_circle_contours(final_sheet)\n",
    "  \n",
    "  # calculating mistakes and final score\n",
    "  mistakes = len(final_contours)\n",
    "  total_questions = len(master_contours)\n",
    "  print(f'total_questions: {total_questions}, mistakes: {mistakes}')\n",
    "  final_score = ((total_questions - mistakes) / total_questions) * 100\n",
    "  print(f'final score: {final_score}')\n",
    "\n",
    "  student_correction = cv2.cvtColor(new_student, cv2.COLOR_GRAY2BGR)\n",
    "  student_correction = draw_full_contours(master_contours, student_correction)\n",
    "\n",
    "  return final_score, student_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial image (778, 1600, 3) processed to (465, 856)\n",
      "Initial image (684, 1600, 3) processed to (410, 776)\n",
      "Initial image (806, 1600, 3) processed to (483, 910)\n",
      "Initial image (808, 1600, 3) processed to (471, 888)\n",
      "Initial image (742, 1600, 3) processed to (445, 853)\n",
      "Initial image (680, 1600, 3) processed to (415, 781)\n",
      "Initial image (808, 1600, 3) processed to (486, 910)\n",
      "Initial image (770, 1600, 3) processed to (460, 872)\n",
      "Initial image (766, 1600, 3) processed to (459, 865)\n",
      "Initial image (752, 1600, 3) processed to (453, 856)\n",
      "Initial image (762, 1600, 3) processed to (453, 859)\n",
      "Initial image (794, 1600, 3) processed to (479, 899)\n",
      "Initial image (764, 1600, 3) processed to (453, 855)\n",
      "Initial image (718, 1600, 3) processed to (428, 809)\n",
      "Initial image (740, 1600, 3) processed to (438, 820)\n",
      "Initial image (760, 1600, 3) processed to (451, 851)\n",
      "Initial image (784, 1600, 3) processed to (478, 890)\n",
      "Initial image (740, 1600, 3) processed to (446, 837)\n",
      "Initial image (758, 1600, 3) processed to (461, 874)\n",
      "Initial image (766, 1600, 3) processed to (468, 867)\n",
      "Initial image (754, 1600, 3) processed to (449, 839)\n",
      "Initial image (668, 1600, 3) processed to (402, 760)\n",
      "Initial image (730, 1600, 3) processed to (441, 822)\n",
      "Initial image (788, 1600, 3) processed to (468, 878)\n",
      "Initial image (764, 1600, 3) processed to (454, 852)\n",
      "Initial image (754, 1600, 3) processed to (453, 850)\n",
      "Initial image (738, 1600, 3) processed to (440, 817)\n",
      "Initial image (738, 1600, 3) processed to (440, 821)\n",
      "Initial image (788, 1600, 3) processed to (472, 885)\n",
      "Initial image (752, 1600, 3) processed to (458, 856)\n",
      "Initial image (800, 1600, 3) processed to (486, 904)\n",
      "Initial image (754, 1600, 3) processed to (457, 857)\n",
      "Initial image (790, 1600, 3) processed to (473, 892)\n",
      "Initial image (728, 1600, 3) processed to (442, 824)\n",
      "Initial image (802, 1600, 3) processed to (480, 899)\n",
      "Initial image (732, 1600, 3) processed to (434, 813)\n",
      "Initial image (758, 1600, 3) processed to (453, 841)\n",
      "Initial image (726, 1600, 3) processed to (430, 803)\n",
      "Initial image (768, 1600, 3) processed to (458, 855)\n",
      "Initial image (758, 1600, 3) processed to (454, 842)\n",
      "Initial image (800, 1600, 3) processed to (483, 899)\n",
      "Initial image (798, 1600, 3) processed to (463, 870)\n",
      "Initial image (800, 1600, 3) processed to (470, 877)\n",
      "Initial image (678, 1600, 3) processed to (401, 757)\n",
      "Initial image (762, 1600, 3) processed to (446, 835)\n",
      "Initial image (746, 1600, 3) processed to (439, 826)\n",
      "Initial image (760, 1600, 3) processed to (456, 839)\n",
      "Initial image (694, 1600, 3) processed to (412, 778)\n",
      "Initial image (778, 1600, 3) processed to (466, 861)\n",
      "Initial image (750, 1600, 3) processed to (447, 834)\n",
      "Initial image (758, 1600, 3) processed to (452, 850)\n",
      "Initial image (712, 1600, 3) processed to (423, 790)\n",
      "Initial image (738, 1600, 3) processed to (451, 821)\n",
      "Initial image (720, 1600, 3) processed to (426, 804)\n",
      "Initial image (752, 1600, 3) processed to (454, 851)\n",
      "Initial image (780, 1600, 3) processed to (461, 873)\n",
      "Initial image (754, 1600, 3) processed to (445, 832)\n",
      "Initial image (710, 1600, 3) processed to (420, 789)\n",
      "Initial image (784, 1600, 3) processed to (463, 871)\n",
      "Initial image (744, 1600, 3) processed to (433, 813)\n",
      "Initial image (688, 1600, 3) processed to (413, 782)\n",
      "Initial image (776, 1600, 3) processed to (461, 873)\n",
      "Initial image (742, 1600, 3) processed to (445, 842)\n",
      "Initial image (782, 1600, 3) processed to (457, 860)\n",
      "Initial image (784, 1600, 3) processed to (463, 874)\n",
      "Initial image (784, 1600, 3) processed to (470, 885)\n",
      "Initial image (794, 1600, 3) processed to (473, 878)\n",
      "Initial image (764, 1600, 3) processed to (449, 846)\n",
      "Initial image (700, 1600, 3) processed to (413, 782)\n",
      "Initial image (756, 1600, 3) processed to (453, 845)\n",
      "Initial image (778, 1600, 3) processed to (473, 863)\n",
      "Initial image (768, 1600, 3) processed to (451, 853)\n",
      "Initial image (736, 1600, 3) processed to (432, 816)\n",
      "Initial image (776, 1600, 3) processed to (462, 864)\n",
      "Initial image (774, 1600, 3) processed to (465, 868)\n",
      "Initial image (750, 1600, 3) processed to (450, 840)\n",
      "Initial image (820, 1600, 3) processed to (487, 912)\n",
      "Initial image (732, 1600, 3) processed to (437, 817)\n",
      "Initial image (706, 1600, 3) processed to (416, 786)\n",
      "Initial image (794, 1600, 3) processed to (478, 902)\n",
      "Initial image (748, 1600, 3) processed to (444, 832)\n",
      "Initial image (746, 1600, 3) processed to (446, 834)\n",
      "Initial image (750, 1600, 3) processed to (462, 834)\n",
      "Initial image (706, 1600, 3) processed to (415, 789)\n",
      "Initial image (732, 1600, 3) processed to (436, 827)\n",
      "Initial image (692, 1600, 3) processed to (411, 772)\n",
      "Initial image (758, 1600, 3) processed to (446, 841)\n",
      "Initial image (738, 1600, 3) processed to (440, 831)\n",
      "Initial image (712, 1600, 3) processed to (427, 804)\n",
      "Initial image (754, 1600, 3) processed to (451, 844)\n",
      "Initial image (762, 1600, 3) processed to (456, 862)\n",
      "Initial image (698, 1600, 3) processed to (414, 782)\n",
      "Initial image (754, 1600, 3) processed to (457, 850)\n",
      "Initial image (742, 1600, 3) processed to (446, 836)\n",
      "Initial image (780, 1600, 3) processed to (463, 874)\n",
      "Initial image (702, 1600, 3) processed to (421, 773)\n",
      "Initial image (688, 1600, 3) processed to (417, 781)\n",
      "Initial image (710, 1600, 3) processed to (419, 792)\n",
      "Initial image (786, 1600, 3) processed to (473, 893)\n",
      "Initial image (812, 1600, 3) processed to (484, 906)\n",
      "Initial image (822, 1600, 3) processed to (487, 915)\n",
      "Images have been transformed and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "raw_dir = 'C:/Users/vian8/Desktop/Tugas2/SNAPGRADE/inputs/cross_data_raw'\n",
    "cropped_directory = 'C:/Users/vian8/Desktop/Tugas2/SNAPGRADE/inputs/cross_data_cropped'\n",
    "os.makedirs(cropped_directory, exist_ok=True)\n",
    "\n",
    "files = os.listdir(raw_dir)\n",
    "image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "\n",
    "for i, filename in enumerate(image_files, start=1):\n",
    "    old_path = os.path.join(raw_dir, filename)\n",
    "    input_image = cv2.imread(old_path)\n",
    "\n",
    "    if input_image is None:\n",
    "        print(f\"Error loading image: {old_path}\")\n",
    "        continue\n",
    "    \n",
    "    cropped_image = automatic_warp_transformation(input_image)\n",
    "\n",
    "    file_extension = os.path.splitext(filename)[1]\n",
    "    new_filename = f\"{i}{file_extension}\"\n",
    "    new_path = os.path.join(cropped_directory, new_filename)\n",
    "\n",
    "    cv2.imwrite(new_path, cropped_image)\n",
    "\n",
    "print(\"Images have been transformed and saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fall_detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
