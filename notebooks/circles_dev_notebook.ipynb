{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RVGZgcQQzyJp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9.0\n",
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "print(cv2.__version__)\n",
    "print(np.__version__)\n",
    "\n",
    "def resize_image(image, target_size=(800, 1000)):\n",
    "  '''Resize the image while maintaining aspect ratio'''\n",
    "  h, w = image.shape[:2]\n",
    "  scale = min(target_size[1] / w, target_size[0] / h)\n",
    "  new_w = int(w * scale)\n",
    "  new_h = int(h * scale)\n",
    "  resized_image = cv2.resize(image, (new_w, new_h))\n",
    "  return resized_image\n",
    "\n",
    "def logarithmic_transformation(image, epsilon=1e-5):\n",
    "  '''Apply logarithmic transformation to the image with zero value handling'''\n",
    "  c = 255 / np.log(1 + np.max(image))\n",
    "  # Epsilon zero-handling technique\n",
    "  log_image = c * (np.log(1 + image + epsilon))\n",
    "  log_image = np.array(log_image, dtype=np.uint8)\n",
    "\n",
    "  return log_image\n",
    "\n",
    "def contrast_stretching(image):\n",
    "  min_val = np.min(image)\n",
    "  max_val = np.max(image)\n",
    "  stretched = (image - min_val) * (255 / (max_val - min_val))\n",
    "  return stretched.astype(np.uint8)\n",
    "\n",
    "def gaussian_blur(image, mode='Default'):\n",
    "  if mode == 'Default':\n",
    "    kernel_size = (3,3)\n",
    "  elif mode == 'Medium':\n",
    "    kernel_size = (5,5)\n",
    "  elif mode == 'Hard':\n",
    "    kernel_size = (7,7)\n",
    "  else:\n",
    "    raise ValueError(\"Mode must be 'Default', 'Medium', or 'Hard'\")\n",
    "\n",
    "  return cv2.GaussianBlur(image, kernel_size, 0)\n",
    "\n",
    "def otsu_thresholding(image):\n",
    "  _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "  return binary_image\n",
    "\n",
    "def canny_edge_detection(image, low_threshold=50, high_threshold=150):\n",
    "  return cv2.Canny(image, low_threshold, high_threshold)\n",
    "\n",
    "def find_extreme_corners(contours):\n",
    "  '''Find the extreme corners of the image'''\n",
    "  all_points = np.vstack(contours)\n",
    "  top_left = all_points[np.argmin(all_points[:, :, 0] + all_points[:, :, 1])]\n",
    "  bottom_right = all_points[np.argmax(all_points[:, :, 0] + all_points[:, :, 1])]\n",
    "  top_right = all_points[np.argmax(all_points[:, :, 0] - all_points[:, :, 1])]\n",
    "  bottom_left = all_points[np.argmin(all_points[:, :, 0] - all_points[:, :, 1])]\n",
    "  return top_left[0], top_right[0], bottom_left[0], bottom_right[0]\n",
    "\n",
    "def apply_perspective_transformation(image, corners):\n",
    "  '''Apply perspective transformation to the image'''\n",
    "  tl, tr, bl, br = corners\n",
    "  width = int(max(np.linalg.norm(br - bl), np.linalg.norm(tr - tl)))\n",
    "  height = int(max(np.linalg.norm(tr - br), np.linalg.norm(tl - bl)))\n",
    "\n",
    "  dst_pts = np.array([\n",
    "      [0, 0],\n",
    "      [width - 1, 0],\n",
    "      [0, height - 1],\n",
    "      [width - 1, height - 1]\n",
    "  ], dtype=\"float32\")\n",
    "\n",
    "  src_pts = np.array([tl, tr, bl, br], dtype=\"float32\")\n",
    "\n",
    "  M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "  warped = cv2.warpPerspective(image, M, (width, height))\n",
    "  return warped\n",
    "\n",
    "def automatic_warp_transformation(image, target_size=(800, 1000)):\n",
    "  '''Automatic Cropping using Adaptive Warp Transformation'''\n",
    "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  resized_image = resize_image(gray_image, target_size)\n",
    "  brightened_image = logarithmic_transformation(resized_image)\n",
    "  contrast_image = contrast_stretching(brightened_image)\n",
    "  blurred_image = gaussian_blur(contrast_image, mode='Default')\n",
    "  binary_image = otsu_thresholding(blurred_image)\n",
    "  edges = canny_edge_detection(binary_image)\n",
    "  contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  # Getting Contours (Drawing Contours in image, useful for debugging)\n",
    "  contour_image = cv2.cvtColor(binary_image, cv2.COLOR_GRAY2BGR)\n",
    "  cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "  corners = find_extreme_corners(contours)\n",
    "  for corner in corners:\n",
    "      cv2.circle(contour_image, tuple(corner), 5, (0, 0, 255), -1)\n",
    "\n",
    "  warped_image = apply_perspective_transformation(resized_image, corners)\n",
    "  print(f'Initial image {image.shape} processed to {warped_image.shape}')\n",
    "\n",
    "  return warped_image\n",
    "\n",
    "def image_uniformization(master_image, student_image):\n",
    "  '''Precision Image Resizing'''\n",
    "  master_shape = master_image.shape\n",
    "  student_shape = student_image.shape\n",
    "\n",
    "  master_height = master_shape[0]\n",
    "  master_width = master_shape[1]\n",
    "\n",
    "  student_height = student_shape[0]\n",
    "  student_width = student_shape[1]\n",
    "\n",
    "  min_height = min(master_height, student_height)\n",
    "  min_width = min(master_width, student_width)\n",
    "\n",
    "  resized_master = cv2.resize(master_image, (min_width, min_height))\n",
    "  resized_student = cv2.resize(student_image, (min_width, min_height))\n",
    "\n",
    "  print(f'master_key {master_image.shape} and student_answer {student_image.shape} uniformed to {resized_master.shape}')\n",
    "\n",
    "  return resized_master, resized_student\n",
    "\n",
    "def morph_open(image):\n",
    "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "  eroded_img = cv2.erode(image, kernel, iterations = 1)\n",
    "  dilated_img = cv2.dilate(eroded_img, kernel, iterations = 1)\n",
    "\n",
    "  return dilated_img\n",
    "\n",
    "def core_circles_preprocessing(image):\n",
    "  '''Core Circles Preprocessing Module'''\n",
    "  blurred_img = gaussian_blur(image, mode='Hard')\n",
    "  contrast_img = contrast_stretching(blurred_img)\n",
    "  log_img = logarithmic_transformation(contrast_img)\n",
    "  binary_img = otsu_thresholding(log_img)\n",
    "  opened_img = morph_open(binary_img)\n",
    "\n",
    "  return opened_img\n",
    "\n",
    "def draw_full_contours(contours, cont_image, radius = 7):\n",
    "  '''Draw Full Circles'''\n",
    "  for contour in contours:\n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] != 0:\n",
    "      cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "      cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "      # Draw a filled circle at the center of the contour\n",
    "      cv2.circle(cont_image, (cX, cY), radius, (0, 255, 0), -1)\n",
    "\n",
    "  return cont_image\n",
    "\n",
    "def extract_and_draw_contours(image):\n",
    "  contours, hierarchy = cv2.findContours(image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  unique_values = []\n",
    "  for columns in image:\n",
    "    for pixel in columns:\n",
    "      if pixel not in unique_values:\n",
    "        unique_values.append(pixel)\n",
    "\n",
    "  contour_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "  # # draw filled circles\n",
    "  # cv2.drawContours(contour_image, contours, -1, (0, 255, 0), thickness = -1)\n",
    "  # # draw hollow circles\n",
    "  # cv2.drawContours(contour_image, contours, -1, (0, 255, 0), thickness = 2)\n",
    "\n",
    "  # draw full contours\n",
    "  contour_image = draw_full_contours(contours, contour_image)\n",
    "\n",
    "  return contours, contour_image\n",
    "\n",
    "def final_scoring(new_student, processed_student, master_contours):\n",
    "  '''Final Score Calculation'''\n",
    "  test_answer = processed_student.copy()\n",
    "  # drawing the Answer Key to the Student's test answer, extracting the mistakes information\n",
    "  check_answers = draw_full_contours(master_contours, test_answer)\n",
    "\n",
    "  # open the image to remove noise\n",
    "  final_sheet = morph_open(check_answers)\n",
    "\n",
    "  # fetching mistakes contours\n",
    "  final_contours, _ = extract_and_draw_contours(final_sheet)\n",
    "\n",
    "  # calculating mistakes and final score\n",
    "  mistakes = len(final_contours)\n",
    "  total_questions = len(master_contours)\n",
    "  final_score = ((total_questions - mistakes) / total_questions) * 100\n",
    "  print(f'final score: {final_score}')\n",
    "\n",
    "  student_correction = cv2.cvtColor(new_student, cv2.COLOR_GRAY2BGR)\n",
    "  student_correction = draw_full_contours(master_contours, student_correction)\n",
    "\n",
    "  return final_score, student_correction\n",
    "\n",
    "def show_image(image): \n",
    "  cv2.imshow('image', image)\n",
    "  cv2.waitKey(0)\n",
    "  cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WKYf3xvatO3S"
   },
   "outputs": [],
   "source": [
    "answer1 = cv2.imread('inputs/circle_1/stu_good_light.jpg')\n",
    "master_sheet = cv2.imread('inputs/circle_1/master_circle_best.jpg')\n",
    "\n",
    "# answer1 = cv2.imread('inputs/circle_2/student.jpg')\n",
    "# master_sheet = cv2.imread('inputs/circle_2/master.jpg')\n",
    "\n",
    "# show_image(answer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUqLtFg8_c1i",
    "outputId": "be452cae-073f-4828-fd7d-5099bf2f6980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial image (3839, 1036, 3) processed to (776, 188)\n",
      "Initial image (3832, 1021, 3) processed to (781, 189)\n"
     ]
    }
   ],
   "source": [
    "student1 = automatic_warp_transformation(answer1)\n",
    "master_key = automatic_warp_transformation(master_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7VAquYPGpoi",
    "outputId": "cc902744-e2aa-443f-a0a3-c7fe9f8ff5f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master_key (781, 189) and student_answer (776, 188) uniformed to (776, 188)\n"
     ]
    }
   ],
   "source": [
    "new_master, new_student = image_uniformization(master_key, student1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rowAXxz4JVok"
   },
   "outputs": [],
   "source": [
    "processed_master = core_circles_preprocessing(new_master)\n",
    "processed_student = core_circles_preprocessing(new_student)\n",
    "\n",
    "# cv2_imshow(processed_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KbvWadNhhIwS",
    "outputId": "ecc5ddd6-a5c6-4551-eccb-9a48c4ba4fbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "student_contours, student_contour_image = extract_and_draw_contours(processed_student)\n",
    "master_contours, master_contour_image = extract_and_draw_contours(processed_master)\n",
    "\n",
    "print(len(student_contours))\n",
    "print(len(master_contours))\n",
    "\n",
    "# cv2_imshow(student_contour_image)\n",
    "\n",
    "# contours, hierarchy = cv2.findContours(processed_student, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# unique_values = []\n",
    "# for columns in processed_student:\n",
    "#   for pixel in columns:\n",
    "#     if pixel not in unique_values:\n",
    "#       unique_values.append(pixel)\n",
    "\n",
    "# print(len(contours))\n",
    "# print(type(contours))\n",
    "# print(unique_values)\n",
    "\n",
    "# # Draw the contours on a copy of the original image\n",
    "# contour_image = cv2.cvtColor(processed_student, cv2.COLOR_GRAY2BGR)  # Convert to BGR for color drawing\n",
    "# cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 3)  # Green color for contours\n",
    "\n",
    "# # Display the image with contours\n",
    "# cv2_imshow(contour_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "id": "JZTRUNuRASrh",
    "outputId": "45037df4-3e01-46da-ccb3-3240c20147a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final score: 86.0\n"
     ]
    }
   ],
   "source": [
    "stu_final_score, stu_answer_key = final_scoring(new_student, processed_student, master_contours)\n",
    "cv2.imshow(\"student's answer vs master key: \", stu_answer_key)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fall_detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
